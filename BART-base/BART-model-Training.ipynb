{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde297c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cbcf55-4776-4dee-9622-870464004153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "device_name = torch.cuda.get_device_name()\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e061039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e28ea7",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24833201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_dataset('wikisql', split='train')\n",
    "val_data = load_dataset('wikisql', split='validation')\n",
    "test_data = load_dataset('wikisql', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5010c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOK = '[SOS] '\n",
    "def format_dataset(example):\n",
    "     return {'input': START_TOK+example['question'], 'target': example['sql']['human_readable']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8f4763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '[SOS] Tell me what the notes are for South Australia ',\n",
       " 'target': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)\n",
    "val_data = val_data.map(format_dataset, remove_columns=val_data.column_names)\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee5ca",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbe48a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75c4e5c91434474bfa2381af2e1d46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9575e88d6c6b46619ceb4d9e3d924dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CHECKPOINT = \"facebook/bart-base\"\n",
    "tokenizer = BartTokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58957174",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finding appropriate Max_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf6abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map article and summary len to dict as well as if sample is longer than 512 tokens\n",
    "def map_to_length(x):\n",
    "    x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
    "    x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
    "    x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
    "    x[\"input_longer_32\"] = int(x[\"input_len\"] > 32)\n",
    "\n",
    "    x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
    "    x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
    "    x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
    "    x[\"out_longer_32\"] = int(x[\"out_len\"] > 32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422e5216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9384f1350fd04e6a89c3fa4f571e1cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/56355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stats = train_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c045f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2142999363eb4875b55cd82689bebaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_stats = val_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6124d3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eff93c3bcb42f080b4129d2e8dafa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/15878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stats = test_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d676baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = concatenate_datasets([train_stats,\n",
    "                                   val_stats,\n",
    "                                  test_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82314c8",
   "metadata": {},
   "source": [
    "##### Some Analysis on lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d491e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_print_stats(x, sample_size):\n",
    "    if len(x[\"input_len\"]) == sample_size:\n",
    "        print(\n",
    "            \"Input Max: {}, Input Mean: {:.5f}, Input>32:{},  Input>128:{:.5f}, Input>64:{:.5f} \\nOutput Max: {}, Output Mean:{:.5f}, Output>32:{}, Output>128:{:.5f}, Output>64:{:.5f}\".format(\n",
    "                max(x[\"input_len\"]),\n",
    "                sum(x[\"input_len\"]) / sample_size,\n",
    "                sum(x[\"input_longer_32\"]) / sample_size,\n",
    "                sum(x[\"input_longer_128\"]) / sample_size,\n",
    "                sum(x[\"input_longer_64\"]) / sample_size,\n",
    "                max(x[\"out_len\"]),\n",
    "                sum(x[\"out_len\"]) / sample_size,\n",
    "                sum(x[\"out_longer_32\"]) / sample_size,\n",
    "                sum(x[\"out_longer_128\"]) / sample_size,\n",
    "                sum(x[\"out_longer_64\"]) / sample_size,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "889acf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c963f3c87b145fa9a12d9b506636072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80654 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 106, Input Mean: 21.46123, Input>32:0.057914052619832866,  Input>128:0.00000, Input>64:0.00041 \n",
      "Output Max: 149, Output Mean:16.98596, Output>32:0.015857861978327174, Output>128:0.00002, Output>64:0.00032\n"
     ]
    }
   ],
   "source": [
    "# All Data\n",
    "output = all_merged.map(\n",
    "  lambda x: compute_and_print_stats(x, all_merged.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a2bc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76a5b405d314e68a6700af8099fc6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 106, Input Mean: 21.44598, Input>32:0.05681838346198208,  Input>128:0.00000, Input>64:0.00041 \n",
      "Output Max: 149, Output Mean:16.98566, Output>32:0.015420104693461095, Output>128:0.00004, Output>64:0.00035\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "output = train_stats.map(\n",
    "  lambda x: compute_and_print_stats(x, train_stats.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08c8537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293a7043234f405c8311fcbde2eae0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 83, Input Mean: 21.49792, Input>32:0.057712860705379405,  Input>128:0.00000, Input>64:0.00036 \n",
      "Output Max: 78, Output Mean:16.87341, Output>32:0.014843842774017338, Output>128:0.00000, Output>64:0.00012\n"
     ]
    }
   ],
   "source": [
    "# Val Data\n",
    "output = val_stats.map(\n",
    "  lambda x: compute_and_print_stats(x, val_stats.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca0894",
   "metadata": {},
   "source": [
    "### Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd20f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2 # start end tokens\n",
    "MAX_LENGTH = 64 + BUFFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0289a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids'],\n",
    "        'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb6381e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b36a1395f48efaf8a4504aca6a839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/56355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c6ce10c5f2493a8bdce40bb792f84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finaltrain_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names, num_proc=4)\n",
    "finalval_data = val_data.map(convert_to_features, batched=True, remove_columns=val_data.column_names, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a80f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75f7aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain_data.set_format(type='torch', columns=columns, device=device)\n",
    "finalval_data.set_format(type='torch', columns=columns, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af0ecff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0, 10975,   104,  3196,   742,   653,    16,     5,   595,   651,\n",
       "           147,     5,    92,   651,   880,    11,   502,  1466,   116,     2,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1], device='cuda:0'),\n",
       " torch.Size([66]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltrain_data[1]['input_ids'], finaltrain_data[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47b2e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[SOS] Tell me what the notes are for South Australia </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(finaltrain_data[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64581c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e34499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/athani.sh/Config_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70bc2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(model_dir,\n",
    "                               dataloader_pin_memory=False,\n",
    "                               fp16=True,  # Use mixed precision training (requires GPU with Tensor Cores)\n",
    "                                per_device_train_batch_size=100,  # Adjust batch size based on your GPU memory\n",
    "                                per_device_eval_batch_size=100,\n",
    "                                gradient_accumulation_steps=2,  # Accumulate gradients to increase effective batch size\n",
    "                                evaluation_strategy=\"steps\",\n",
    "                                eval_steps=500,\n",
    "                                logging_steps=100,\n",
    "                                save_steps=500,\n",
    "                                save_total_limit=2,  # Limit the total number of checkpoints\n",
    "                                load_best_model_at_end=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5136c98-3aa6-43d1-8207-ca97eb58bfba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953a51fc4d34184bdec3ecc1d87cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athani.sh/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(CHECKPOINT, device_map=device)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=finaltrain_data,\n",
    "    eval_dataset=finalval_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d974c98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='846' max='846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [846/846 18:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>0.094992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=846, training_loss=0.462212065432934, metrics={'train_runtime': 1102.2449, 'train_samples_per_second': 153.382, 'train_steps_per_second': 0.768, 'total_flos': 6644156469350400.0, 'train_loss': 0.462212065432934, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4268fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('/home/athani.sh/Model_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461cf48",
   "metadata": {},
   "source": [
    "## Generating SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ea6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_sql(local_model, text):\n",
    "    inputs = tokenizer(text, padding='longest', max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    output = local_model.generate(input_ids, attention_mask=attention_mask, max_length=64)\n",
    "\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_sql_on_test(data, local_model):\n",
    "    length = data.shape[0]\n",
    "    query = data['input']\n",
    "    expected = data['target']\n",
    "        \n",
    "    for i in range(length):\n",
    "        print(f\"QUERY - {query[i]}\")\n",
    "        translated = translate_to_sql(local_model, query[i])\n",
    "        print(f\"Prediction - {translated}\")\n",
    "        print(f\"Expected = {expected[i]}\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa4a4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY - [SOS] What is terrence ross' nationality\n",
      "Prediction - SELECT Nationality FROM table WHERE Player = Terrence Ross\n",
      "Expected = SELECT Nationality FROM table WHERE Player = Terrence Ross\n",
      "==================================================\n",
      "QUERY - [SOS] What clu was in toronto 1995-96\n",
      "Prediction - SELECT Clu FROM table WHERE Year = 1995-96 AND City = Toronto\n",
      "Expected = SELECT School/Club Team FROM table WHERE Years in Toronto = 1995-96\n",
      "==================================================\n",
      "QUERY - [SOS] which club was in toronto 2003-06\n",
      "Prediction - SELECT Club FROM table WHERE Venue = toronto 2003-06\n",
      "Expected = SELECT School/Club Team FROM table WHERE Years in Toronto = 2003-06\n",
      "==================================================\n",
      "QUERY - [SOS] how many schools or teams had jalen rose\n",
      "Prediction - SELECT COUNT School/Team FROM table WHERE Player = Jalen Rose\n",
      "Expected = SELECT COUNT School/Club Team FROM table WHERE Player = Jalen Rose\n",
      "==================================================\n",
      "QUERY - [SOS] Where was Assen held?\n",
      "Prediction - SELECT Location FROM table WHERE Team = Assen\n",
      "Expected = SELECT Round FROM table WHERE Circuit = Assen\n",
      "==================================================\n",
      "QUERY - [SOS] What was the number of race that Kevin Curtain won?\n",
      "Prediction - SELECT COUNT Race FROM table WHERE Winning driver = Kevin Curtain\n",
      "Expected = SELECT COUNT No FROM table WHERE Pole Position = Kevin Curtain\n",
      "==================================================\n",
      "QUERY - [SOS] What was the date of the race in Misano?\n",
      "Prediction - SELECT Date FROM table WHERE Location = misano\n",
      "Expected = SELECT Date FROM table WHERE Circuit = Misano\n",
      "==================================================\n",
      "QUERY - [SOS] How many different positions did Sherbrooke Faucons (qmjhl) provide in the draft?\n",
      "Prediction - SELECT COUNT Position FROM table WHERE Name = sherbrooke faucons (qmjhl)\n",
      "Expected = SELECT COUNT Position FROM table WHERE College/junior/club team = Sherbrooke Faucons (QMJHL)\n",
      "==================================================\n",
      "QUERY - [SOS] What are the nationalities of the player picked from Thunder Bay Flyers (ushl)\n",
      "Prediction - SELECT Nationality FROM table WHERE NHL team = thunder bay flyers (ushl)\n",
      "Expected = SELECT Nationality FROM table WHERE College/junior/club team = Thunder Bay Flyers (USHL)\n",
      "==================================================\n",
      "QUERY - [SOS] How many different college/junior/club teams provided a player to the Washington Capitals NHL Team?\n",
      "Prediction - SELECT COUNT College/Junior/Club Team FROM table WHERE NHL Team = Washington Capitals NHL\n",
      "Expected = SELECT COUNT College/junior/club team FROM table WHERE NHL team = Washington Capitals\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "generate_sql_on_test(test_data.select(range(10)), model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5651889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
