{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e2619e-1266-4972-9fa2-a321fb1d6d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets transformers==4.39.2\n",
    "#!pip install sentencepiece\n",
    "#!pip install accelerate -U\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fde297c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cbcf55-4776-4dee-9622-870464004153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-12GB'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e061039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e28ea7",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24833201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_dataset('wikisql', split='train')\n",
    "val_data = load_dataset('wikisql', split='validation')\n",
    "test_data = load_dataset('wikisql', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ef2363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phase': 1,\n",
       " 'question': 'Tell me what the notes are for South Australia ',\n",
       " 'table': {'header': ['State/territory',\n",
       "   'Text/background colour',\n",
       "   'Format',\n",
       "   'Current slogan',\n",
       "   'Current series',\n",
       "   'Notes'],\n",
       "  'page_title': '',\n",
       "  'page_id': '',\n",
       "  'types': ['text', 'text', 'text', 'text', 'text', 'text'],\n",
       "  'id': '1-1000181-1',\n",
       "  'section_title': '',\n",
       "  'caption': '',\n",
       "  'rows': [['Australian Capital Territory',\n",
       "    'blue/white',\n",
       "    'Yaa·nna',\n",
       "    'ACT · CELEBRATION OF A CENTURY 2013',\n",
       "    'YIL·00A',\n",
       "    'Slogan screenprinted on plate'],\n",
       "   ['New South Wales',\n",
       "    'black/yellow',\n",
       "    'aa·nn·aa',\n",
       "    'NEW SOUTH WALES',\n",
       "    'BX·99·HI',\n",
       "    'No slogan on current series'],\n",
       "   ['New South Wales',\n",
       "    'black/white',\n",
       "    'aaa·nna',\n",
       "    'NSW',\n",
       "    'CPX·12A',\n",
       "    'Optional white slimline series'],\n",
       "   ['Northern Territory',\n",
       "    'ochre/white',\n",
       "    'Ca·nn·aa',\n",
       "    'NT · OUTBACK AUSTRALIA',\n",
       "    'CB·06·ZZ',\n",
       "    'New series began in June 2011'],\n",
       "   ['Queensland',\n",
       "    'maroon/white',\n",
       "    'nnn·aaa',\n",
       "    'QUEENSLAND · SUNSHINE STATE',\n",
       "    '999·TLG',\n",
       "    'Slogan embossed on plate'],\n",
       "   ['South Australia',\n",
       "    'black/white',\n",
       "    'Snnn·aaa',\n",
       "    'SOUTH AUSTRALIA',\n",
       "    'S000·AZD',\n",
       "    'No slogan on current series'],\n",
       "   ['Victoria',\n",
       "    'blue/white',\n",
       "    'aaa·nnn',\n",
       "    'VICTORIA - THE PLACE TO BE',\n",
       "    'ZZZ·562',\n",
       "    'Current series will be exhausted this year']],\n",
       "  'name': 'table_1000181_1'},\n",
       " 'sql': {'human_readable': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA',\n",
       "  'sel': 5,\n",
       "  'agg': 0,\n",
       "  'conds': {'column_index': [3],\n",
       "   'operator_index': [0],\n",
       "   'condition': ['SOUTH AUSTRALIA']}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5010c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOK = '[SOS] '\n",
    "def format_dataset(example):\n",
    "    return {'input': START_TOK+example['question'], 'target': example['sql']['human_readable']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8f4763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '[SOS] Tell me what the notes are for South Australia ',\n",
       " 'target': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)\n",
    "val_data = val_data.map(format_dataset, remove_columns=val_data.column_names)\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "\n",
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee5ca",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbe48a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = 'google-t5/t5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58957174",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finding appropriate Max_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf6abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map article and summary len to dict as well as if sample is longer than 512 tokens\n",
    "def map_to_length(x):\n",
    "    x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
    "    x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
    "    x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
    "    x[\"input_longer_32\"] = int(x[\"input_len\"] > 32)\n",
    "\n",
    "    x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
    "    x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
    "    x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
    "    x[\"out_longer_32\"] = int(x[\"out_len\"] > 32)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422e5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c045f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_stats = val_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6124d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = test_data.map(map_to_length, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d676baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = concatenate_datasets([train_stats,\n",
    "                                   val_stats,\n",
    "                                  test_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82314c8",
   "metadata": {},
   "source": [
    "##### Some Analysis on lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d491e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_print_stats(x, sample_size):\n",
    "    if len(x[\"input_len\"]) == sample_size:\n",
    "        print(\n",
    "            \"Input Max: {}, Input Mean: {:.5f}, Input>32:{},  Input>128:{:.5f}, Input>64:{:.5f} \\nOutput Max: {}, Output Mean:{:.5f}, Output>32:{}, Output>128:{:.5f}, Output>64:{:.5f}\".format(\n",
    "                max(x[\"input_len\"]),\n",
    "                sum(x[\"input_len\"]) / sample_size,\n",
    "                sum(x[\"input_longer_32\"]) / sample_size,\n",
    "                sum(x[\"input_longer_128\"]) / sample_size,\n",
    "                sum(x[\"input_longer_64\"]) / sample_size,\n",
    "                max(x[\"out_len\"]),\n",
    "                sum(x[\"out_len\"]) / sample_size,\n",
    "                sum(x[\"out_longer_32\"]) / sample_size,\n",
    "                sum(x[\"out_longer_128\"]) / sample_size,\n",
    "                sum(x[\"out_longer_64\"]) / sample_size,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889acf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cd9da41ec149e289a189cdc8f19206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80654 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 94, Input Mean: 21.73463, Input>32:0.07684677759317579,  Input>128:0.00000, Input>64:0.00046 \n",
      "Output Max: 176, Output Mean:21.57647, Output>32:0.05963746373397476, Output>128:0.00002, Output>64:0.00035\n"
     ]
    }
   ],
   "source": [
    "# All Data\n",
    "output = all_merged.map(\n",
    "  lambda x: compute_and_print_stats(x, all_merged.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05a2bc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2d255e425f4db6b3ac488611170a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 94, Input Mean: 21.71997, Input>32:0.07614231212847129,  Input>128:0.00000, Input>64:0.00043 \n",
      "Output Max: 176, Output Mean:21.57257, Output>32:0.05971076213290746, Output>128:0.00004, Output>64:0.00032\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "output = train_stats.map(\n",
    "  lambda x: compute_and_print_stats(x, train_stats.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d08c8537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61730be61b4447f285b4725c81dd12dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Max: 83, Input Mean: 21.78126, Input>32:0.07552547203420021,  Input>128:0.00000, Input>64:0.00071 \n",
      "Output Max: 79, Output Mean:21.45707, Output>32:0.05640660254126588, Output>128:0.00000, Output>64:0.00059\n"
     ]
    }
   ],
   "source": [
    "# Val Data\n",
    "output = val_stats.map(\n",
    "  lambda x: compute_and_print_stats(x, val_stats.shape[0]), \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bca0894",
   "metadata": {},
   "source": [
    "### Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd20f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2 # start end tokens\n",
    "MAX_LENGTH = 64 + BUFFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0289a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids'],\n",
    "        'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6381e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names, num_proc=4)\n",
    "finalval_data = val_data.map(convert_to_features, batched=True, remove_columns=val_data.column_names, num_proc=4)\n",
    "#finaltest_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a80f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75f7aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltrain_data.set_format(type='torch', columns=columns, device=device)\n",
    "finalval_data.set_format(type='torch', columns=columns, device=device)\n",
    "#finaltest_data.set_format(type='torch', columns=columns, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af0ecff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 784,  134, 3638,  908,  363,   19,    8,  750,  939,  213,    8,  126,\n",
       "          939, 1553,   16, 1515, 2722,   58,    1,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0], device='cuda:0'),\n",
       " torch.Size([66]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltrain_data[1]['input_ids'], finaltrain_data[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47b2e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SOS] Tell me what the notes are for South Australia</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(finaltrain_data[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca3bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d64581c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e34499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = f\"./t5-checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70bc2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(model_dir,\n",
    "                               dataloader_pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12919c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(CHECKPOINT, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96dda5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhal.n/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=finaltrain_data,\n",
    "    eval_dataset=finalval_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d974c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamanrocks1999\u001b[0m (\u001b[33mneu_nmnsnghl\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/singhal.n/TEXT2SQL/wandb/run-20240413_225609-gk88swum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/neu_nmnsnghl/huggingface/runs/gk88swum\" target=\"_blank\">dashing-cosmos-3</a></strong> to <a href=\"https://wandb.ai/neu_nmnsnghl/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21135' max='21135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21135/21135 42:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.194300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.187800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.167200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21135, training_loss=0.19133752615761468, metrics={'train_runtime': 2590.2534, 'train_samples_per_second': 65.27, 'train_steps_per_second': 8.159, 'total_flos': 2949576308490240.0, 'train_loss': 0.19133752615761468, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4268fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./t5-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461cf48",
   "metadata": {},
   "source": [
    "## Generating SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02ea6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_sql(local_model, text):\n",
    "    inputs = tokenizer(text, padding='longest', max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    output = local_model.generate(input_ids, attention_mask=attention_mask, max_length=64)\n",
    "\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_sql_on_test(data, local_model):\n",
    "    length = data.shape[0]\n",
    "    query = data['input']\n",
    "    expected = data['target']\n",
    "        \n",
    "    for i in range(length):\n",
    "        print(f\"QUERY - {query[i]}\")\n",
    "        translated = translate_to_sql(local_model, query[i])\n",
    "        print(f\"Prediction - {translated}\")\n",
    "        print(f\"Expected = {expected[i]}\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0aa4a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY - [SOS] What is terrence ross' nationality\n",
      "Prediction - SELECT Nationality FROM table WHERE Name = terrence ross\n",
      "Expected = SELECT Nationality FROM table WHERE Player = Terrence Ross\n",
      "==================================================\n",
      "QUERY - [SOS] What clu was in toronto 1995-96\n",
      "Prediction - SELECT clu FROM table WHERE Location = toronto 1995-96\n",
      "Expected = SELECT School/Club Team FROM table WHERE Years in Toronto = 1995-96\n",
      "==================================================\n",
      "QUERY - [SOS] which club was in toronto 2003-06\n",
      "Prediction - SELECT Club FROM table WHERE Location = toronto 2003-06\n",
      "Expected = SELECT School/Club Team FROM table WHERE Years in Toronto = 2003-06\n",
      "==================================================\n",
      "QUERY - [SOS] how many schools or teams had jalen rose\n",
      "Prediction - SELECT COUNT Schools/Teams FROM table WHERE Player = Jalen Rose\n",
      "Expected = SELECT COUNT School/Club Team FROM table WHERE Player = Jalen Rose\n",
      "==================================================\n",
      "QUERY - [SOS] Where was Assen held?\n",
      "Prediction - SELECT Venue FROM table WHERE Team = assen\n",
      "Expected = SELECT Round FROM table WHERE Circuit = Assen\n",
      "==================================================\n",
      "QUERY - [SOS] What was the number of race that Kevin Curtain won?\n",
      "Prediction - SELECT COUNT Race FROM table WHERE Winner = kryn curtain\n",
      "Expected = SELECT COUNT No FROM table WHERE Pole Position = Kevin Curtain\n",
      "==================================================\n",
      "QUERY - [SOS] What was the date of the race in Misano?\n",
      "Prediction - SELECT Date FROM table WHERE Venue = misano\n",
      "Expected = SELECT Date FROM table WHERE Circuit = Misano\n",
      "==================================================\n",
      "QUERY - [SOS] How many different positions did Sherbrooke Faucons (qmjhl) provide in the draft?\n",
      "Prediction - SELECT COUNT Position FROM table WHERE Player = Sherbrooke Faucons (Qmjhl)\n",
      "Expected = SELECT COUNT Position FROM table WHERE College/junior/club team = Sherbrooke Faucons (QMJHL)\n",
      "==================================================\n",
      "QUERY - [SOS] What are the nationalities of the player picked from Thunder Bay Flyers (ushl)\n",
      "Prediction - SELECT Nationality FROM table WHERE Pick = Thunder Bay Flyers (ushl)\n",
      "Expected = SELECT Nationality FROM table WHERE College/junior/club team = Thunder Bay Flyers (USHL)\n",
      "==================================================\n",
      "QUERY - [SOS] How many different college/junior/club teams provided a player to the Washington Capitals NHL Team?\n",
      "Prediction - SELECT COUNT College/junior/club team FROM table WHERE NHL team = Washington Capitals\n",
      "Expected = SELECT COUNT College/junior/club team FROM table WHERE NHL team = Washington Capitals\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: \\ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)\r"
     ]
    }
   ],
   "source": [
    "generate_sql_on_test(test_data.select(range(10)), model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5651889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
