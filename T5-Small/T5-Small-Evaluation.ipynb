{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad39232-1329-4f16-813a-e317281f51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93ebbe2-c491-4388-a679-fbfe29a63bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab35654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nmnsnghl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1633a94e-e4ce-4182-bdf4-f28a3307725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab46245-d96e-46c6-bfa8-629913346565",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset('wikisql', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b620720-7fdb-48a8-a848-08d8bf2dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOK = '[SOS] '\n",
    "def format_dataset(example):\n",
    "    return {'input': START_TOK+example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f506e3-fe5a-4e7b-969f-6a0b84438aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2 # start end tokens\n",
    "MAX_LENGTH = 64 + BUFFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d94328-060a-4b02-9e67-85e41ae60dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = 'google-t5/t5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977835e4-3ef4-43d3-a92a-14d922227e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids'],\n",
    "        'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922399d5-65ba-4156-8bf7-4eb399ce503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltest_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334b5305-3ad1-4f62-b6ac-0b328d838800",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "finaltest_data.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f3ab05-398b-4ff2-8ede-e26ca1612df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = './t5-model'\n",
    "model = T5ForConditionalGeneration.from_pretrained(local, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14873a3b-8863-4227-acfc-c00f9a8e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(finaltest_data, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e242d123-bd3c-4527-bef6-5d256a7dc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "709185d4-4c82-4d01-9298-ebd31bead020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming testdata is a DataLoader that batches your Dataset\n",
    "total_loss = 0\n",
    "total_bleu = 0\n",
    "total_meteor = 0\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients in evaluation\n",
    "    for batch in test_dl:\n",
    "        # Send your batch of inputs to the device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, decoder_attention_mask=decoder_attention_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute BLEU score\n",
    "        predictions = outputs.logits.argmax(-1)  # Get the model's predictions\n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            # Convert tensors to lists\n",
    "            prediction = prediction.tolist()\n",
    "            label = label.tolist()\n",
    "\n",
    "            # Compute the BLEU score between the predicted and actual sentence\n",
    "            bleu_score = sentence_bleu([label], prediction)\n",
    "            total_bleu += bleu_score\n",
    "            \n",
    "            label_str = list(map(lambda x: str(x),label))\n",
    "            prediction_str = list(map(lambda x: str(x),prediction))\n",
    "            # Compute the Meteor score between the predicted and actual sentence\n",
    "            meteor_scr = meteor_score([label_str], prediction_str)\n",
    "            total_meteor += meteor_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d119d1-68ae-4acf-b2fc-59a81cecc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.002602017767439262, Average BLEU score: 0.94424568132835, Average Meteor score: 0.9748364119186308\n"
     ]
    }
   ],
   "source": [
    "# Compute the average loss and BLEU score over all the batches\n",
    "avg_loss = total_loss / finaltest_data.shape[0]\n",
    "avg_bleu = total_bleu / finaltest_data.shape[0]\n",
    "avg_meteor = total_meteor / finaltest_data.shape[0]\n",
    "\n",
    "print(f'Average loss: {avg_loss}, Average BLEU score: {avg_bleu}, Average Meteor score: {avg_meteor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223d1ec-7947-4659-903f-bb55124d88e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_temp",
   "language": "python",
   "name": "torch_temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
